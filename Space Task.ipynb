{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d3ceaa",
   "metadata": {},
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "f1fb1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "94186dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\irakl\\Desktop\\assignment\\data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7034d004",
   "metadata": {},
   "source": [
    "### Data type changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "b65c6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = df.copy(deep = True)\n",
    "df_json['id'] = df_json['id'].astype('int')\n",
    "df_json['application_date_timestamp'] =  df_json['application_date'].apply(lambda x: pd.Timestamp(x))\n",
    "df_json['application_date_short_timestamp'] = df_json['application_date_timestamp'].dt.tz_localize(None).dt.strftime('%Y-%m-%d %H:%M:%S.%f').str[:-3]. \\\n",
    "apply (lambda x: pd.Timestamp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2264a",
   "metadata": {},
   "source": [
    "### JSON flattening process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "b3df8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast JSON data to dictionaries using json.loads() function\n",
    "df_json_to_dict = df_json['contracts'].apply(lambda x: json.loads(x) if isinstance(x, str) else {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "90455633",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Flatten JSON using pd.json_normalize() function\n",
    "df_json_normalized = df_json_to_dict.apply(lambda x: pd.json_normalize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "0e0ac01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result was series of DataFrames. \n",
    "#Creation of one uniform Dataframe column from series objects is possible by stacking series \n",
    "if isinstance(df_json_normalized, pd.Series):\n",
    "    # Convert the Series of DataFrames to a list of DataFrames\n",
    "    df_json_normalized_list = df_json_normalized.tolist()\n",
    "    #Keeping Dataframe Number by assigning index to DataFrame is essential to keep track of the user_id (df['id']) \n",
    "    df_json_normalized_list = [df.assign(list_index=i) for i, df in enumerate(df_json_normalized_list)]\n",
    "    #Concatenate the list into a single DataFrame\n",
    "    df_combined = pd.concat(df_json_normalized_list, ignore_index=True)\n",
    "else:\n",
    "    #If it's already a DataFrame, no need to concatenate\n",
    "    df_combined = df_json_normalized\n",
    "\n",
    "#Merge with the original DataFrame\n",
    "#Create explicit index for merge. This index can be used as a join on parameter \n",
    "df_json = df_json.reset_index()\n",
    "#Merge on indicies\n",
    "df_combined_final = pd.merge(\n",
    "     df_json.drop(columns=['contracts']),  \n",
    "    df_combined,                      \n",
    "    left_on='index',                     \n",
    "    right_on='list_index',             \n",
    "    how='inner'                        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "9dedee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing empty strings and true null values with pandas NA value\n",
    "df_combined_final['contract_id'] = df_combined_final['contract_id'].apply(lambda x: pd.NA if pd.isnull(x) or x=='' else x)\n",
    "df_combined_final['bank'] = df_combined_final['bank'].apply(lambda x: pd.NA if pd.isnull(x) or x=='' else x)\n",
    "df_combined_final['summa'] = df_combined_final['summa'].apply(lambda x: pd.NA if pd.isnull(x) or x=='' else x)\n",
    "df_combined_final['loan_summa'] = df_combined_final['loan_summa'].apply(lambda x: pd.NA if pd.isnull(x) or x=='' else x)\n",
    "df_combined_final['claim_date'] = df_combined_final['claim_date'].apply(lambda x: pd.NA if pd.isnull(x) or x=='' else x)\n",
    "df_combined_final['claim_id'] = df_combined_final['claim_id'].apply(lambda x: pd.NA if pd.isnull(x) or x=='' else x)\n",
    "df_combined_final['contract_date'] = df_combined_final['contract_date'].apply(lambda x: pd.NA if pd.isnull(x) or x=='' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac259049",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba25c3a",
   "metadata": {},
   "source": [
    "#### Same steps works for all the features. Copying flattened Data, filtering and grouping it "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631af76b",
   "metadata": {},
   "source": [
    "### Total Claims Count 280 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "83a78bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_claims_raw =  df_combined_final.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "f4bb396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_claims_filtered = feature_claims_raw.loc[(pd.to_datetime(feature_claims_raw['claim_date'], format= '%d.%m.%Y') >=  pd.Timestamp.now()- pd.Timedelta(days=280))  & (feature_claims_raw['claim_date'].notna()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "008b8edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_claims_grouped = feature_claims_filtered[['id','claim_date']].groupby('id').count()\n",
    "feature_claims_grouped.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477633b3",
   "metadata": {},
   "source": [
    "### Sum of Exposure of loans WO TBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "484910b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_exposure_raw =  df_combined_final.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "a7165005",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_exposure_filtered = feature_exposure_raw.loc[(~feature_exposure_raw['bank'].isin(['LIZ', 'LOM', 'MKO', 'SUG', pd.NA]))\\\n",
    "&  (feature_exposure_raw['contract_date'].notna()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "01e90bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_exposure_grouped =feature_exposure_filtered[['id', 'loan_summa']].groupby('id').sum()\n",
    "feature_exposure_grouped.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044e2c92",
   "metadata": {},
   "source": [
    "### Number of Days Since Last Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "380a224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_last_loan_raw =  df_combined_final.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "9d9a4d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_last_loan_filtered = feature_last_loan_raw.loc[feature_last_loan_raw['summa'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "30c14318",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_last_loan_grouped = feature_last_loan_filtered[['id','application_date_short_timestamp', 'contract_date']].groupby(['id','application_date_short_timestamp']). \\\n",
    "agg({\n",
    "    'contract_date': 'max'})\n",
    "feature_last_loan_grouped.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "1b0fc4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_last_loan_grouped['days_since_last_loan']=(feature_last_loan_grouped['application_date_short_timestamp'] - pd.to_datetime(feature_last_loan_grouped['contract_date'], format= '%d.%m.%Y')).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6108787",
   "metadata": {},
   "source": [
    "## Data Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "8905632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = df_json.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "e86e74fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial and claims feature merge \n",
    "df_result = pd.merge(\n",
    "    df_initial.drop(columns=['contracts']), \n",
    "    feature_claims_grouped,                     \n",
    "    left_on='id',                  \n",
    "    right_on='id',    \n",
    "    how='left'    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "63aac064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result and exposure feature merge\n",
    "df_result = pd.merge(\n",
    "    df_result, \n",
    "    feature_exposure_grouped,                     \n",
    "    left_on='id',                  \n",
    "    right_on='id',    \n",
    "    how='left'    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "80fbfbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result and last loan feature merge \n",
    "df_result = pd.merge(\n",
    "    df_result, \n",
    "    feature_last_loan_grouped,                     \n",
    "    left_on='id',                  \n",
    "    right_on='id',    \n",
    "    how='left'    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "af096580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning up all unnecessary columns and renaming them \n",
    "df_result = df_result.drop(['index', 'application_date', 'application_date_short_timestamp_y', 'contract_date', 'application_date_timestamp'],axis =1 )\n",
    "df_result = df_result.rename(columns={\n",
    "    'application_date_short_timestamp_x': 'application_date',\n",
    "    'claim_date': 'number_of_claims',\n",
    "    'loan_summa': 'total_exposure'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c86aa",
   "metadata": {},
   "source": [
    "#### Applying Feature Missing Value Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "f22bea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['number_of_claims'].fillna(-3, inplace = True)\n",
    "df_result['number_of_claims'] = df_result['number_of_claims'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "bf827f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['total_exposure'] = df_result.apply(lambda row: row['total_exposure'] \n",
    "        if not pd.isna(row['total_exposure']) else -3 if row['number_of_claims'] ==-3 else -100 if (pd.isna(row['total_exposure'])) & (not pd.isna(row['days_since_last_loan'])) else  -1 if pd.isna(row['total_exposure'])   else -1000, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "a10e94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['days_since_last_loan'] = df_result.apply(lambda row: row['days_since_last_loan'] \n",
    "        if not pd.isna(row['days_since_last_loan']) else -3 if row['number_of_claims'] ==-3 else -1, axis=1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "df779589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to CSV\n",
    "df_result.to_csv('contract_features.csv', index = False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
